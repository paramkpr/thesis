Hierarchical clustering algorithms are extensively utilized in modern
data science across various domains such as healthcare, biology,
recommender systems, criminal justice, and social network
analysis~\cite{chhabra2023}. Unlike flat clustering, hierarchical
methods do not require a pre-specified number of clusters and reveal
hierarchical relationships within the data. Given their widespread
application, especially in sensitive areas where biased data can
perpetuate discrimination, ensuring fairness in hierarchical
clustering is ethically imperative and practically critical.

Fair hierarchical clustering (FHC) incorporates explicit fairness
constraints into the clustering process, aiming to produce
hierarchies fair at every resolution level. This approach ensures
that each internal cluster node satisfies fairness constraints,
addressing biases at each merge or split decision throughout the
clustering tree.

\subsection{Problem Formulation}

Formally defined by Ahmadian et al.~\cite{ahmadian2020} and refined
subsequently by Knittel et al.~\cite{knittel2023}, fair hierarchical
clustering ensures proportional representation for protected groups
(e.g., gender or ethnicity) at every cluster within the hierarchy.
Given a dataset $X$ divided into $\lambda$ protected groups, a
hierarchical clustering tree $T$ is fair if, for each non-singleton cluster $C$:
\[
  \alpha_l \leq \frac{|C_l|}{|C|} \leq \beta_l \quad \forall l \in [\lambda],
\]
where $|C_l|$ is the number of elements from group $l$ in cluster
$C$, and $\alpha_l, \beta_l$ represent lower and upper fairness
bounds. A common special case, \emph{proportional fairness}, enforces
each cluster to reflect group proportions close to their overall
distribution in the dataset.

Beyond representational fairness, \emph{relative balance} constraints
have emerged as important. These ensure that sibling clusters
resulting from splits are similar in size, improving interpretability
and avoiding trivial solutions like isolating
singletons~\cite{knittel2023}. However, balancing these constraints
against traditional clustering objectives—such as minimizing
Dasgupta’s cost, defined as \( \sum_{e=(x,y)} w(e) \cdot n_T(e)
\)—remains challenging due to computational complexity and
conflicting local and global optimization requirements~\cite{knittel2023}.

\subsection{Challenges and Implications}

Enforcing fairness recursively at every hierarchical level
significantly complicates the clustering task compared to flat
fairness enforcement. This complexity arises from several critical issues:

\begin{itemize}
  \item \textbf{Conflict with Optimal Cost Objectives:} Fairness
    constraints can necessitate merges or splits that deviate from
    cost-minimizing decisions, introducing a measurable \emph{price
    of fairness}~\cite{ahmadian2020}.
  \item \textbf{Computational Complexity:} The exponential search
    space for fair hierarchies poses significant algorithmic
    challenges, making exact optimization infeasible for large datasets.
  \item \textbf{Diverse Fairness Notions:} Different contexts demand
    varied fairness definitions (e.g., proportionality, bounded
    representation), complicating generalizable algorithmic solutions.
  \item \textbf{Scalability and Interpretability:} Maintaining
    fairness across large, high-dimensional datasets without
    sacrificing interpretability remains an ongoing practical challenge.
\end{itemize}

Nevertheless, research indicates that fairness constraints often
result in only modest cost increases, suggesting their viability in
practice~\cite{knittel2023}.

\subsection{Algorithmic Approaches}

Fair hierarchical clustering algorithms broadly fall into two main
categories: objective-based optimization approaches and procedural
adaptations of standard clustering algorithms.

\paragraph{Objective-Based Optimization Methods.} Ahmadian et
al.~\cite{ahmadian2020} introduced fair hierarchical clustering,
applying fairness constraints directly to hierarchical objectives
like Dasgupta’s cost. Their approach, inspired by fair flat
clustering techniques (e.g., fairlets), primarily handles scenarios
involving two groups and yields relatively high polynomial
approximation factors (e.g., $O(n^{5/6}\cdot \text{polylog}(n))$).

Knittel et al.~\cite{knittel2023} substantially improved upon this by
introducing generalized reduction methods. Their approach transforms
an existing hierarchical clustering into a fair and balanced
hierarchy through \emph{tree operators}, including Subtree
Deletion/Insertion and Shallow Tree Folding. This method achieves a
polylogarithmic approximation factor ($O(\log^2 n)$) relative to the
optimal unfair clustering cost—significantly narrowing the gap
between fairness-constrained and standard clustering algorithms.
These advances allow handling multiple groups and complex fairness
criteria effectively.

\paragraph{Fair Modifications to HAC.} Contrasting the
optimization-oriented approaches, Chhabra and
Mohapatra~\cite{chhabra2023} propose directly modifying the widely
used Hierarchical Agglomerative Clustering (HAC) algorithm. Their
method integrates fairness checks at each greedy merge step,
independent of linkage criteria (single, complete, or average). The
approach is designed to handle multiple protected groups
simultaneously, maintaining runtime efficiency comparable to
traditional HAC algorithms. Empirical evidence indicates that their
method yields fairer clusterings with relatively minor cost
increments, offering practitioners a simpler, more direct route to
incorporating fairness.

\subsection{Open Questions and Future Directions}

Fair hierarchical clustering remains an active research domain, with
several open questions and avenues for future exploration:

\begin{itemize}
  \item \textbf{Improving Approximation Guarantees:} Narrowing
    existing gaps between fairness-constrained and optimal clustering
    costs remains an important theoretical pursuit.
  \item \textbf{Domain-Specific Fairness Metrics:} Developing methods
    that flexibly accommodate intersecting or overlapping protected
    group definitions is crucial for diverse real-world applications.
  \item \textbf{Scalability and Computational Efficiency:} Further
    advancements in algorithmic efficiency are necessary to apply
    fair clustering to large, complex datasets effectively.
  \item \textbf{Individual-Level Fairness:} Extending hierarchical
    fairness to incorporate individual-level or contextual
    definitions, which better capture granular biases, represents a
    significant challenge.
  \item \textbf{Integrating Additional Ethical Constraints:}
    Exploring how fairness can coexist with interpretability,
    accountability, and transparency will be critical in ethically
    sensitive applications.
\end{itemize}

Overall, fair hierarchical clustering represents an essential
advancement in ethical unsupervised learning. By carefully balancing
fairness constraints and clustering objectives, researchers and
practitioners can foster more equitable data-driven decision-making
across various sensitive domains.
